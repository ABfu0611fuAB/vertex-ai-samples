{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Using Vertex AI Matching Engine for StackOverflow Questions\n",
        "![ ](https://www.google-analytics.com/collect?v=2&tid=G-L6X3ECH596&cid=1&en=page_view&sid=1&dt=sdk_matching_engine_create_stack_overflow_embeddings.ipynb&dl=notebooks%2Fofficial%2Fmatching_engine%2Fsdk_matching_engine_create_stack_overflow_embeddings.ipynb)\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_create_stack_overflow_embeddings.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_create_stack_overflow_embeddings.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "      <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/matching_engine/sdk_matching_engine_create_stack_overflow_embeddings.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0a74aaf1481"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This example demonstrates how to encode custom text embeddings using the StackOverflow dataset and the sentence-T5 model. These are uploaded to the Vertex AI Matching Engine service. It is a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. Moreover, it is a fully managed offering, further reducing operational overhead. It is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research.\n",
        "\n",
        "**Pre-requisite**: This notebook requires you to already have a VPC network set up. See the \"Prepare a VPC network\" section in [Create Vertex AI Matching Engine index notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb).\n",
        "\n",
        "Learn more about [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34a4b245e795"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to encode custom text embeddings, create an Approximate Nearest Neighbor (ANN) index, and query against indexes.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex AI Matching Engine`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "* Create ANN index\n",
        "* Create an index endpoint with VPC Network\n",
        "* Deploy ANN index\n",
        "* Perform online query\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset used for this tutorial is the [StackOverflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow).\n",
        "\n",
        "> Stack Overflow is the largest online community for programmers to learn, share their knowledge, and advance their careers. Updated on a quarterly basis, this BigQuery dataset includes an archive of Stack Overflow content, including posts, votes, tags, and badges. This dataset is updated to mirror the Stack Overflow content on the Internet Archive, and is also available through the Stack Exchange Data Explorer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0f1bea346db"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the latest version of Cloud Storage, BigQuery, and the Vertex AI SDK for Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfbccc635a17"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade google-cloud-aiplatform \\\n",
        "                        google-cloud-storage \\\n",
        "                        'google-cloud-bigquery[pandas]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ac7ebac10b"
      },
      "source": [
        "Install the latest version of Redis for low-latency data retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3dd53b3c06c"
      },
      "outputs": [],
      "source": [
        "# Install the redis package\n",
        "! pip install --upgrade redis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5263c7eab02"
      },
      "outputs": [],
      "source": [
        "# ! pip install google_cloud_aiplatform-1.25.dev20230502+language.models-py2.py3-none-any.whl \"shapely<2.0.0\" \"protobuf==3.19.6\" --force-reinstall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b08ba354c6e"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bea801acf6b5"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd28c9e4f067"
      },
      "source": [
        "## Before you begin\n",
        "#### Set your project ID\n",
        "\n",
        "If you don't know your project ID, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42635d0c0019"
      },
      "outputs": [],
      "source": [
        "! gcloud config list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "80c0215f05a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"[YOUR-PROJECT-ID]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4512bf63b3"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "474be5183c27"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "949271bfebe3"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b65b4ce80d9a"
      },
      "source": [
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "985cdbfe7372"
      },
      "source": [
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fbc9cd30cc4b"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79efab26ad02"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a336a05c6149"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c0a44fa330f"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3uj8x73nDX_"
      },
      "source": [
        "* Authentication: Rerun the `gcloud auth login` command in the Vertex AI Workbench notebook terminal when you are logged out and need the credential again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating gs://your-bucket-name-plated-life-378620-unique/...\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR6Wwv-hCCN-"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "You will use [Stack Overflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) of question and answers hosted on BigQuery.\n",
        "\n",
        "> This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset.\n",
        "\n",
        "The BigQuery table is too large to fit into memory, so you need to write a generator called `query_bigquery_chunks` to yield chunks of the dataframe for processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ed1b3f87c475"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Any, Generator\n",
        "\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "QUERY_TEMPLATE = \"\"\"\n",
        "        SELECT distinct q.id, q.title, q.body\n",
        "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` where Score>0 ORDER BY View_Count desc) AS q \n",
        "        LIMIT {limit} OFFSET {offset};\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "def query_bigquery_chunks(\n",
        "    max_rows: int, rows_per_chunk: int, start_chunk: int = 0\n",
        ") -> Generator[pd.DataFrame, Any, None]:\n",
        "    for offset in range(start_chunk, max_rows, rows_per_chunk):\n",
        "        query = QUERY_TEMPLATE.format(limit=rows_per_chunk, offset=offset)\n",
        "        query_job = client.query(query)\n",
        "        rows = query_job.result()\n",
        "        df = rows.to_dataframe()\n",
        "        df[\"title_with_body\"] = df.title + \"\\n\" + df.body\n",
        "        yield df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "c700388b9ee6"
      },
      "outputs": [],
      "source": [
        "# Get a dataframe of 1000 rows for demonstration purposes\n",
        "df = next(query_bigquery_chunks(max_rows=1000, rows_per_chunk=1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "b43937b6065d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>title_with_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12615525</td>\n",
              "      <td>What are the different use cases of joblib ver...</td>\n",
              "      <td>&lt;p&gt;Background: I'm just getting started with s...</td>\n",
              "      <td>What are the different use cases of joblib ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12788972</td>\n",
              "      <td>Set database timeout in Entity Framework</td>\n",
              "      <td>&lt;p&gt;My command keeps timing out, so I need to c...</td>\n",
              "      <td>Set database timeout in Entity Framework\\n&lt;p&gt;M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18405374</td>\n",
              "      <td>Test a factory of a 3rd party class</td>\n",
              "      <td>&lt;p&gt;My application uses a third party jar (no a...</td>\n",
              "      <td>Test a factory of a 3rd party class\\n&lt;p&gt;My app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18350790</td>\n",
              "      <td>Sublime Text 3 (and 2): newly installed dictio...</td>\n",
              "      <td>&lt;p&gt;I'm a well-experienced mac user but no prog...</td>\n",
              "      <td>Sublime Text 3 (and 2): newly installed dictio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18695061</td>\n",
              "      <td>Closing dropdown in Spinner in Android</td>\n",
              "      <td>&lt;p&gt;I need to animate an icon of an arrow when ...</td>\n",
              "      <td>Closing dropdown in Spinner in Android\\n&lt;p&gt;I n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                              title  \\\n",
              "0  12615525  What are the different use cases of joblib ver...   \n",
              "1  12788972           Set database timeout in Entity Framework   \n",
              "2  18405374                Test a factory of a 3rd party class   \n",
              "3  18350790  Sublime Text 3 (and 2): newly installed dictio...   \n",
              "4  18695061             Closing dropdown in Spinner in Android   \n",
              "\n",
              "                                                body  \\\n",
              "0  <p>Background: I'm just getting started with s...   \n",
              "1  <p>My command keeps timing out, so I need to c...   \n",
              "2  <p>My application uses a third party jar (no a...   \n",
              "3  <p>I'm a well-experienced mac user but no prog...   \n",
              "4  <p>I need to animate an icon of an arrow when ...   \n",
              "\n",
              "                                     title_with_body  \n",
              "0  What are the different use cases of joblib ver...  \n",
              "1  Set database timeout in Entity Framework\\n<p>M...  \n",
              "2  Test a factory of a 3rd party class\\n<p>My app...  \n",
              "3  Sublime Text 3 (and 2): newly installed dictio...  \n",
              "4  Closing dropdown in Spinner in Android\\n<p>I n...  "
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Examine the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "2cacd9869ee5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract the question ids and question text\n",
        "ids = df.id.tolist()\n",
        "questions = df.title.tolist()\n",
        "\n",
        "# Verify the length\n",
        "len(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1124422cc200"
      },
      "source": [
        "#### Instantiate the text encoding model\n",
        "\n",
        "Use the [PaLM](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings) API developed by Google for converting text to embeddings.\n",
        "\n",
        "> Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
        "> - Semantic search: Search text ranked by semantic similarity.\n",
        "> - Recommendation: Return items with text attributes similar to the given text.\n",
        "> - Classification: Return the class of items whose text attributes are similar to the given text.\n",
        "> - Clustering: Cluster items whose text attributes are similar to the given text.\n",
        "> - Outlier Detection: Return items where text attributes are least related to the given text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43088937e820"
      },
      "source": [
        "#### Defining an encoding function\n",
        "\n",
        "Define a function to be used later that will take sentences and convert them to embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "5c4520ae99f8"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "# Load the PaLM API embedding model\n",
        "from vertexai.preview.language_models import TextEmbeddingModel\n",
        "\n",
        "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-001\")\n",
        "\n",
        "# Define an embedding method that uses the model\n",
        "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
        "    try:\n",
        "        embeddings = model.get_embeddings(sentences)\n",
        "        return [embedding.values for embedding in embeddings]\n",
        "    except Exception:\n",
        "        return [None for _ in range(len(sentences))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "a0370bd840d2"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import Any, Generator, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# Generator function to yield batches of sentences\n",
        "def generate_batches(\n",
        "    sentences: List[str], batch_size: int\n",
        ") -> Generator[List[str], None, None]:\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        yield sentences[i : i + batch_size]\n",
        "\n",
        "\n",
        "def encode_text_to_embedding_batched(\n",
        "    sentences: List[str], api_calls_per_second: int = 10, batch_size: int = 5\n",
        ") -> Tuple[List[bool], np.ndarray]:\n",
        "\n",
        "    embeddings_list: List[List[float]] = []\n",
        "\n",
        "    # Prepare the batches using a generator\n",
        "    batches = generate_batches(sentences, batch_size)\n",
        "\n",
        "    seconds_per_job = 1 / api_calls_per_second\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for batch in tqdm(\n",
        "            batches, total=math.ceil(len(sentences) / batch_size), position=0\n",
        "        ):\n",
        "            futures.append(\n",
        "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
        "            )\n",
        "            time.sleep(seconds_per_job)\n",
        "\n",
        "        for future in futures:\n",
        "            embeddings_list.extend(future.result())\n",
        "\n",
        "    is_successful = [\n",
        "        embedding is not None for sentence, embedding in zip(sentences, embeddings_list)\n",
        "    ]\n",
        "    embeddings_list_successful = np.squeeze(\n",
        "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
        "    )\n",
        "    return is_successful, embeddings_list_successful"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba45d58bf96e"
      },
      "source": [
        "#### Test the encoding function\n",
        "\n",
        "Encode a subset of data and see if the embeddings and distance metrics make sense.\n",
        "\n",
        "According to the [embedding documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings#colab_example_of_semantic_search_using_embeddings), the similarity of embeddings is calculated using the dot-product. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "9b01baa906b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cce1b5098184983b0a2fa752cd9d8e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Encode a subset of questions for validation\n",
        "questions = df.title.tolist()[:500]\n",
        "is_successful, question_embeddings = encode_text_to_embedding_batched(\n",
        "    sentences=df.title.tolist()[:500]\n",
        ")\n",
        "\n",
        "# Filter for successfully embedded sentences\n",
        "questions = np.array(questions)[is_successful]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3761f56648b"
      },
      "source": [
        "Save the dimension size for later usage when creating the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "d296e181205d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 221,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DIMENSIONS = len(question_embeddings[0])\n",
        "\n",
        "DIMENSIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "95e408daf219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query question = SignalR - connection.hubName is undefined\n",
            "\t0: SignalR - connection.hubName is undefined: 0.9999994517616809\n",
            "\t1: How to solve a login/database missing error regarding Sitecore Training Website?: 0.6360554028470855\n",
            "\t2: NameError: name 'helloworld' is not defined: 0.6137728867637725\n",
            "\t3: Cannot Resolve @style/Theme.Sherlock: 0.6077803902687016\n",
            "\t4: Load an assembly (dll) from a network drive in C#: 0.6053678317274827\n",
            "\t5: OleDbException: No value given for one or more required parameters: 0.6047448126425075\n",
            "\t6: C# HTTPModule Could not load type CGI Request: 0.6003740454733572\n",
            "\t7: SecurityException - Dapper on shared hosting: 0.5930472323803362\n",
            "\t8: Wix 3.5 preprocessor extension - undefined preprocessor function: 0.5873751287246225\n",
            "\t9: need to parse refname in post-receive script: 0.5854348455753308\n",
            "\t10: @Url.Content not encoding text - ASP.NET MVC with Razor: 0.5845889360671046\n",
            "\t11: The symbol you provided is not a function: 0.58359112051759\n",
            "\t12: SharePoint Redirect site logo link to the root site collection home page: 0.5829007492528733\n",
            "\t13: PHP WebSocketServer can't connect to WebKit (Safari): 0.5823678399403036\n",
            "\t14: Trouble with PayPal Adaptive Payments in Node.js: 0.5792609168047103\n",
            "\t15: Push Notification not Receiving after bb10 restart in Android Runtime: 0.5770136072688865\n",
            "\t16: Best way to not run rufus-scheduler when starting a rails console: 0.5768953788628541\n",
            "\t17: Ruby gem error: no such file to load -- bundler: 0.5742615556787587\n",
            "\t18: Cannot load drivers for SQL Server on WSO2 Data Services Server: 0.5699260860941642\n",
            "\t19: jQuery.getJSON callback does not fire in IE7: 0.5693486248098263\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "question_index = random.randint(0, 99)\n",
        "\n",
        "print(f\"Query question = {questions[question_index]}\")\n",
        "scores = np.dot(question_embeddings[question_index], question_embeddings.T)\n",
        "\n",
        "# Print top 20 matches\n",
        "for index, (question, score) in enumerate(\n",
        "    sorted(zip(questions, scores), key=lambda x: x[1], reverse=True)[:20]\n",
        "):\n",
        "    print(f\"\\t{index}: {question}: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQIQSyF9GtSv"
      },
      "source": [
        "#### Save the embeddings in JSONL format.\n",
        "\n",
        "The data must be formatted in JSONL format, which means each embedding dictionary is written as a JSON string on its own line.\n",
        "\n",
        "See more information in the docs at [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup#input-data-format)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "7c1193aca5d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings directory: /var/tmp/tmpb4hc2lc4\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Create temporary file to write embeddings to\n",
        "embeddings_file_path = Path(tempfile.mkdtemp())\n",
        "\n",
        "print(f\"Embeddings directory: {embeddings_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "279c0bbfc6bb"
      },
      "source": [
        "Write embeddings in batches to prevent out-of-memory errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "307f468a3ecd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "024a0651ff5f47caac06ebfbb7828fa9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Chunk of rows from BigQuery:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bcfdbd6fa7f40cf905bb97fd2dcc807",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a462f7ab70d4d15bcaea41046f25e62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22f89967813b4555a614478480f47ea0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33cb4ff9925541f5a0c488e3adab415b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4229ffac6b034d378c90dc1614742f7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80583d4985dc4619a07370952538ee96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eb03c7866514641ac9121f9292771d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "379239dc19a941b2b15b30ba48dc920b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2aea830207c4921b6cb5de65dcaa154",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78f907e0997f45ce8143634424c26c08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b4b5cddb42b46598b69fba31cb05f53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e334194375c45528c93a229683b45c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5e5504fcaec4393bea087729c69d25e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de6b7e8db3d945ee9a2a3a52cc1c3971",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7d8480cd7714681a607ddffe559e58b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dfd38af7c8b4267882fc639bacb815b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c83c5590d8e84128a8b3d33e358545bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9575cd085cc14a67b916721f2212eb8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56929a72676c4bcdb5904baaa006384a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b68edacc275b49e38930220bd9e88790",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5513b9902334491fb94597d204a80cad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub message rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c83263c359a4bcdaff29d75b0d7fb3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3049effc6c744a9b3e4292d0ca1e81a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bb8998744ac42aa8086aeebc02543cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47a40972aa3e46afaccbce3a1cf026e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "525b09cf8d754d7fb0ececa27f3b9245",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0f8150bd4d94bd98d9ef89ae81800c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gc\n",
        "import json\n",
        "\n",
        "BQ_NUM_ROWS = 50000\n",
        "BQ_CHUNK_SIZE = 1000\n",
        "BQ_NUM_CHUNKS = math.ceil(BQ_NUM_ROWS / BQ_CHUNK_SIZE)\n",
        "\n",
        "START_CHUNK = 0\n",
        "\n",
        "# Create a rate limit of 300 requests per minute. Adjust this depending on your quota.\n",
        "API_CALLS_PER_SECOND = 300 / 60\n",
        "# According to the docs, each request can process 5 instances per request\n",
        "ITEMS_PER_REQUEST = 5\n",
        "\n",
        "# Loop through each generated dataframe, convert\n",
        "for i, df in tqdm(\n",
        "    enumerate(\n",
        "        query_bigquery_chunks(\n",
        "            max_rows=BQ_NUM_ROWS, rows_per_chunk=BQ_CHUNK_SIZE, start_chunk=START_CHUNK\n",
        "        )\n",
        "    ),\n",
        "    total=BQ_NUM_CHUNKS - START_CHUNK,\n",
        "    position=-1,\n",
        "    desc=\"Chunk of rows from BigQuery\",\n",
        "):\n",
        "    # Create a unique output file for each chunk\n",
        "    chunk_path = embeddings_file_path.joinpath(\n",
        "        f\"{embeddings_file_path.stem}_{i+START_CHUNK}.json\"\n",
        "    )\n",
        "    with open(chunk_path, \"a\") as f:\n",
        "        id_chunk = df.id\n",
        "\n",
        "        # Convert batch to embeddings\n",
        "        is_successful, question_chunk_embeddings = encode_text_to_embedding_batched(\n",
        "            sentences=df.title_with_body,\n",
        "            api_calls_per_second=API_CALLS_PER_SECOND,\n",
        "            batch_size=ITEMS_PER_REQUEST,\n",
        "        )\n",
        "\n",
        "        # Append to file\n",
        "        embeddings_formatted = [\n",
        "            json.dumps(\n",
        "                {\n",
        "                    \"id\": str(id),\n",
        "                    \"embedding\": [str(value) for value in embedding],\n",
        "                }\n",
        "            )\n",
        "            + \"\\n\"\n",
        "            for id, embedding in zip(id_chunk[is_successful], question_chunk_embeddings)\n",
        "        ]\n",
        "        f.writelines(embeddings_formatted)\n",
        "\n",
        "        # Delete the DataFrame and any other large data structures\n",
        "        del df\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceeda7bb1778"
      },
      "outputs": [],
      "source": [
        "embeddings_file_path.stem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "bd10090aff55"
      },
      "outputs": [],
      "source": [
        "# # ! gsutil ls {remote_folder}\n",
        "# ! gsutil rm -rf {remote_folder}\n",
        "# # embeddings_file_path.parent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuVl8DrWG8NS"
      },
      "source": [
        "Upload the training data to a Google Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "3PgsA_vbI8Vg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CommandException: 1 files/objects could not be removed.\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_0.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_1.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_10.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_11.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_12.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_2.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_20.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_23.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_18.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_25.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_19.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_13.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_21.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_14.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_15.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_22.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_16.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_26.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_17.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_24.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_27.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_28.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_29.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_3.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_30.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_31.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_33.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_32.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_34.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_35.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_36.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_37.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_38.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_39.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_4.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_40.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_41.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_42.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_43.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_44.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_45.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_47.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_46.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_48.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_49.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_6.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_5.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_7.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_8.json [Content-Type=application/json]...\n",
            "Copying file:///var/tmp/tmpb4hc2lc4/tmpb4hc2lc4_9.json [Content-Type=application/json]...\n",
            "- [50/50 files][884.7 MiB/884.7 MiB] 100% Done                                  \n",
            "Operation completed over 50 objects/884.7 MiB.                                   \n"
          ]
        }
      ],
      "source": [
        "remote_folder = f\"{BUCKET_URI}/{embeddings_file_path.stem}/\"\n",
        "! gsutil rm -rf {remote_folder}\n",
        "! gsutil -m cp -r {embeddings_file_path}/* {remote_folder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mglUPwHpJH98"
      },
      "source": [
        "## Create Indexes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIBCQ7dDSbW"
      },
      "source": [
        "### Create ANN Index (for Production Usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "qiIg9b5zJLi1"
      },
      "outputs": [],
      "source": [
        "DISPLAY_NAME = \"stack_overflow_8M\"\n",
        "DESCRIPTION = \"question titles and bodies from stackoverflow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svLYiDf0OD2G"
      },
      "source": [
        "Create the ANN index configuration:\n",
        "\n",
        "To learn more about configuring the index, see [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup#input-data-format).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "Y4zooldkGoM4"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "dffb00b23f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating MatchingEngineIndex\n",
            "Create MatchingEngineIndex backing LRO: projects/782921078983/locations/us-central1/indexes/150193288354201600/operations/5246750946649702400\n",
            "MatchingEngineIndex created. Resource name: projects/782921078983/locations/us-central1/indexes/150193288354201600\n",
            "To use this MatchingEngineIndex in another session:\n",
            "index = aiplatform.MatchingEngineIndex('projects/782921078983/locations/us-central1/indexes/150193288354201600')\n"
          ]
        }
      ],
      "source": [
        "DIMENSIONS = 768\n",
        "\n",
        "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=remote_folder,\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=80,\n",
        "    description=DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "17jrQi501QyX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'projects/782921078983/locations/us-central1/indexes/150193288354201600'"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "INDEX_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1a9fbecabb"
      },
      "source": [
        "Using the resource name, you can retrieve an existing MatchingEngineIndex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "1ddb70647d98"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2xjAnDDObD"
      },
      "source": [
        "## Create an IndexEndpoint with VPC Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "BpZQoJyxDlbO"
      },
      "outputs": [],
      "source": [
        "# # Retrieve the project number\n",
        "# PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
        "# PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "\n",
        "# VPC_NETWORK = \"matching-engine\"\n",
        "# VPC_NETWORK_FULL = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, VPC_NETWORK)\n",
        "# VPC_NETWORK_FULL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "QuARXzJVGyQX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating MatchingEngineIndexEndpoint\n",
            "Create MatchingEngineIndexEndpoint backing LRO: projects/782921078983/locations/us-central1/indexEndpoints/1958951488696877056/operations/3813480365239042048\n",
            "MatchingEngineIndexEndpoint created. Resource name: projects/782921078983/locations/us-central1/indexEndpoints/1958951488696877056\n",
            "To use this MatchingEngineIndexEndpoint in another session:\n",
            "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/782921078983/locations/us-central1/indexEndpoints/1958951488696877056')\n"
          ]
        }
      ],
      "source": [
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    description=DISPLAY_NAME,\n",
        "    # network=VPC_NETWORK_FULL,\n",
        "    public_endpoint_enabled=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "8d60f31de1f4"
      },
      "outputs": [],
      "source": [
        "# my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/782921078983/locations/us-central1/indexEndpoints/1958951488696877056')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np2cgVuuIe9k"
      },
      "source": [
        "## Deploy Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ew1UgcIIiJG"
      },
      "source": [
        "### Deploy ANN Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "8345cf6d87ad"
      },
      "outputs": [],
      "source": [
        "# # DEPLOYED_INDEX_ID = 'stack_overflow_8M_1c74'\n",
        "# import uuid\n",
        "\n",
        "# DEPLOYED_INDEX_ID = f\"stack_overflow_8M_{str(uuid.uuid4())[:4]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "nLOYTGygIlMK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'stack_overflow_8M_d298'"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO\n",
        "DEPLOYED_INDEX_ID = \"deployed_index_id_unique\"\n",
        "\n",
        "DEPLOYED_INDEX_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uK4WOgqN1NG"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbfe4fd103a"
      },
      "source": [
        "#### Verify number of declared items matches the number of embeddings\n",
        "\n",
        "Each IndexEndpoint can have multiple indexes deployed to it. For each index, you can retrieved the number of deployed vectors using the `index_endpoint._gca_resource.index_stats.vectors_count`. The numbers may not match exactly due to potential failures using the embedding service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "93f89a15f642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected: 50000, Actual: 49992\n"
          ]
        }
      ],
      "source": [
        "number_of_vectors = sum(\n",
        "    aiplatform.MatchingEngineIndex(\n",
        "        deployed_index.index\n",
        "    )._gca_resource.index_stats.vectors_count\n",
        "    for deployed_index in my_index_endpoint.deployed_indexes\n",
        ")\n",
        "\n",
        "print(f\"Expected: {BQ_NUM_ROWS}, Actual: {number_of_vectors}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LCGvBNvBd8D"
      },
      "source": [
        "## Create Online Queries\n",
        "\n",
        "After you built your indexes, you may query against the deployed index to find nearest neighbors.\n",
        "\n",
        "Note: For the DOT_PRODUCT_DISTANCE distance type, the \"distance\" property returned with each MatchNeighbor actually refers to the similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "ae9996f185fe"
      },
      "outputs": [],
      "source": [
        "test_embeddings = encode_texts_to_embeddings(sentences=[\"Install GPU for Tensorflow\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "A3KYVw5HB-4v"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[MatchNeighbor(id='68704846', distance=0.7809396386146545),\n",
              "  MatchNeighbor(id='41366327', distance=0.7776130437850952),\n",
              "  MatchNeighbor(id='70984360', distance=0.776228666305542),\n",
              "  MatchNeighbor(id='66525883', distance=0.7567992806434631),\n",
              "  MatchNeighbor(id='47248054', distance=0.7561374306678772),\n",
              "  MatchNeighbor(id='52857901', distance=0.7410272359848022),\n",
              "  MatchNeighbor(id='58525872', distance=0.7396792769432068),\n",
              "  MatchNeighbor(id='61884137', distance=0.7386407852172852),\n",
              "  MatchNeighbor(id='64786672', distance=0.7366656064987183),\n",
              "  MatchNeighbor(id='58561680', distance=0.7357790470123291)]]"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test query\n",
        "NUM_NEIGHBOURS = 10\n",
        "\n",
        "response = my_index_endpoint.find_neighbors(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=test_embeddings,\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2879d3d9ca"
      },
      "source": [
        "Verify that the retrieved results are relevant by checking the StackOverflow link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "7c8682079e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://stackoverflow.com/questions/68704846\n",
            "https://stackoverflow.com/questions/41366327\n",
            "https://stackoverflow.com/questions/70984360\n",
            "https://stackoverflow.com/questions/66525883\n",
            "https://stackoverflow.com/questions/47248054\n",
            "https://stackoverflow.com/questions/52857901\n",
            "https://stackoverflow.com/questions/58525872\n",
            "https://stackoverflow.com/questions/61884137\n",
            "https://stackoverflow.com/questions/64786672\n",
            "https://stackoverflow.com/questions/58561680\n"
          ]
        }
      ],
      "source": [
        "for match_index, neighbor in enumerate(response[0]):\n",
        "    print(f\"https://stackoverflow.com/questions/{neighbor.id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05514825ba7d"
      },
      "source": [
        "## Storing and retrieving titles from a Redis data store\n",
        "When you productionize this code into a service, you will need to convert the nearest nearest id's returned from Vertex AI Matching Engine into data usable by downstream services.\n",
        "\n",
        "In this case, you'll need to convert the id's to titles.\n",
        "\n",
        "You can use Google Cloud's Memorystore to deploy a managed Redis instance to save the id-title key-value pairs.\n",
        "\n",
        "See more information on [Memorystore](https://cloud.google.com/memorystore/docs/redis/create-manage-instances?hl=en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d2b240f0d52"
      },
      "outputs": [],
      "source": [
        "REDIS_INSTANCE_NAME = \"stackoverflow-questions-palm\"\n",
        "\n",
        "# Create a Redis instance\n",
        "! gcloud redis instances create '{REDIS_INSTANCE_NAME}' --size=10 --region='{REGION}' --network='{VPC_NETWORK_FULL}' --connect-mode=private-service-access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "371ccc0d2eb2"
      },
      "outputs": [],
      "source": [
        "# Get host and port info\n",
        "REDIS_HOST = ! gcloud redis instances list --filter=\"INSTANCE_NAME:'{REDIS_INSTANCE_NAME}'\" --region {REGION}  --format='value(HOST)'\n",
        "REDIS_PORT = ! gcloud redis instances list --filter=\"INSTANCE_NAME:'{REDIS_INSTANCE_NAME}'\" --region {REGION} --format='value(PORT)'\n",
        "\n",
        "if isinstance(REDIS_HOST, list):\n",
        "    REDIS_HOST = REDIS_HOST[0]\n",
        "\n",
        "if isinstance(REDIS_PORT, list):\n",
        "    REDIS_PORT = REDIS_PORT[0]\n",
        "\n",
        "print(f\"REDIS_HOST = {REDIS_HOST}\")\n",
        "print(f\"REDIS_PORT = {REDIS_PORT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73796089386a"
      },
      "outputs": [],
      "source": [
        "# Connect to the instance\n",
        "import redis\n",
        "\n",
        "redis_client = redis.StrictRedis(host=REDIS_HOST, port=REDIS_PORT)\n",
        "# redis_client.flushdb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f000f5432d13"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Convert the id -> title relationship into a dict and write to redis\n",
        "for df in tqdm(\n",
        "    query_bigquery_chunks(\n",
        "        max_rows=BQ_NUM_ROWS, rows_per_chunk=BQ_CHUNK_SIZE, start_chunk=0\n",
        "    ),\n",
        "    total=BQ_NUM_CHUNKS,\n",
        "    position=0,\n",
        "    desc=\"Chunk of rows from BigQuery\",\n",
        "):\n",
        "    ids = df.id.tolist()\n",
        "    titles = df.title.tolist()\n",
        "    bodies = df.body.tolist()\n",
        "\n",
        "    # create a Redis pipeline\n",
        "    pipe = redis_client.pipeline()\n",
        "\n",
        "    # iterate over the data and add hset commands to the pipeline\n",
        "    for (id, title, body) in tqdm(zip(ids, titles, bodies), total=len(ids), position=1):\n",
        "        pipe.hset(\n",
        "            str(id),\n",
        "            mapping={\n",
        "                \"title\": str(title),\n",
        "                \"body\": str(body[:100]),\n",
        "            },\n",
        "        )\n",
        "\n",
        "    # execute the pipeline\n",
        "    _ = pipe.execute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1f8b396aeb1"
      },
      "outputs": [],
      "source": [
        "# Verify that redis can retrieve the correct information\n",
        "df = next(query_bigquery_chunks(max_rows=10, rows_per_chunk=10))\n",
        "\n",
        "[\n",
        "    f\"Actual = {title}, Retrieved = {redis_client.hgetall(str(id))}\"\n",
        "    for id, title in zip(df.id, df.title)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "You can also manually delete resources that you created by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Force undeployment of indexes and delete endpoint\n",
        "my_index_endpoint.delete(force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omj7N9iWv-Tq"
      },
      "outputs": [],
      "source": [
        "# Delete indexes\n",
        "tree_ah_index.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2fcf9468031"
      },
      "outputs": [],
      "source": [
        "# Delete redis instance\n",
        "! gcloud redis instances delete '{REDIS_INSTANCE_NAME}' --region {REGION} --quiet"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk_matching_engine_create_stack_overflow_embeddings_palm.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
