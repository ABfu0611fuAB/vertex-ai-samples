{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Using Vertex AI Feature Store with Pandas Dataframe\n",
        "\n",
        "<table align=\"left\">\n",
        "    <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "    \n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> \n",
        "        Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook introduces Pandas support for Feature Store using Vertex AI SDK. For pre-requisites and introduction on Vertex AI SDK and Feature Store native support, please go through this [Colab notebook](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/feature_store/sdk-feature-store.ipynb). \n",
        "\n",
        "Learn more about [Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxF5JWRVT5PP"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to use `Vertex AI Feature Store` with pandas Dataframe.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- Vertex AI Feature Store\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Ingest Feature values from Pandas DataFrame into Feature Store's Entity types.\n",
        "- Read Entity feature values from Online Feature Store into Pandas DataFrame.\n",
        "- Batch serve feature values from your Feature Store into Pandas DataFrame.\n",
        "\n",
        "You also learn how Vertex AI Feature Store can be useful in the below scenarios:\n",
        "\n",
        "- Online serving with updated feature values.\n",
        "- Point-in-time correctness to fetch feature values for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ZNLaf6T0lN"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial is a part of the Feature Store tutorial notebooks. It uses a movie recommendation dataset as an example for demonstrating various functionalities of Feature Store. The original task is to train a model to predict if a user is going to watch a movie, and serve the model online."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W2Bj_QpT2Ud"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEdiXsJg0XY"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install additional packages\n",
        "\n",
        "To run this notebook, you need to install the following packages for Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet --upgrade google-cloud-aiplatform \\\n",
        "                                google-cloud-bigquery \\\n",
        "                                google-cloud-bigquery-storage \\\n",
        "                                avro \\\n",
        "                                pyarrow \\\n",
        "                                pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "restart"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-ZBOjErv5mM"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfEglUHQk9S3"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "region"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcp_authenticate"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below.\n",
        "\n",
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated.\n",
        "\n",
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce6043da7b33"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0367eac06a10"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ad4dbb4a61"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13224697bfb"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bucket:mbsdk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_bucket"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_bucket"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdct_Lm7x2I_"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from avro.datafile import DataFileReader\n",
        "from avro.io import DatumReader\n",
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "138407556b22"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d2077ffee78"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buQBIv3ZL3A0"
      },
      "source": [
        "## Create a Feature Store\n",
        "\n",
        "The method to create a Feature Store in Vertex AI returns a\n",
        "[long-running operation](https://google.aip.dev/151) (LRO). An LRO starts an asynchronous job. LROs are returned for other API methods too, such as updating or deleting a featurestore. \n",
        "\n",
        "Running the code cell below creates a featurestore and prints the process' logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6uIWQeoBSr8"
      },
      "outputs": [],
      "source": [
        "# Create featurestore\n",
        "movie_predictions_feature_store = aiplatform.Featurestore.create(\n",
        "    featurestore_id=\"movie_predictions\", online_store_fixed_node_count=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpmJq75zXjmT"
      },
      "source": [
        "## Create Entity types\n",
        "\n",
        "Entity types can be created within the Featurestore class. Below, you create the `Users` entity type and `Movies` entity type. Process logs are printed in the output for each cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU0oXvINBgPV"
      },
      "outputs": [],
      "source": [
        "# Create users entity type\n",
        "users_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"users\",\n",
        "    description=\"Users entity\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPCGFznrFwFy"
      },
      "outputs": [],
      "source": [
        "# Create movies entity type\n",
        "movies_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"movies\",\n",
        "    description=\"Movies entity\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJW4q-0jO2Xf"
      },
      "source": [
        "## Create Features\n",
        "Features can be created within each entity type. Add defined features to the `Users` entity type and `Movies` entity type by using the following methods.\n",
        "\n",
        "### Add features using *create_feature* method\n",
        "Provide the feature information like id, type and description to the `create_feature` method of entity type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvjwT84iVSps"
      },
      "outputs": [],
      "source": [
        "# Create age feature\n",
        "users_feature_age = users_entity_type.create_feature(\n",
        "    feature_id=\"age\",\n",
        "    value_type=\"INT64\",\n",
        "    description=\"User age\",\n",
        ")\n",
        "\n",
        "# Create gender feature\n",
        "users_feature_gender = users_entity_type.create_feature(\n",
        "    feature_id=\"gender\",\n",
        "    value_type=\"STRING\",\n",
        "    description=\"User gender\",\n",
        ")\n",
        "\n",
        "# Create liked_genres feature\n",
        "users_feature_liked_genres = users_entity_type.create_feature(\n",
        "    feature_id=\"liked_genres\",\n",
        "    value_type=\"STRING_ARRAY\",\n",
        "    description=\"An array of genres this user liked\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecb141839033"
      },
      "source": [
        "### Add features using batch method\n",
        "You can also create features using a config map in a dictionary format and the `batch_create_features` method. This way, you can add multiple features at once. \n",
        "\n",
        "Below, you define and create *title*, *genres* and *average_rating* features using the batch method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llTT9_Dgbac2"
      },
      "outputs": [],
      "source": [
        "movies_feature_configs = {\n",
        "    \"title\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The title of the movie\",\n",
        "    },\n",
        "    \"genres\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The genre of the movie\",\n",
        "    },\n",
        "    \"average_rating\": {\n",
        "        \"value_type\": \"DOUBLE\",\n",
        "        \"description\": \"The average rating for the movie, range is [1.0-5.0]\",\n",
        "    },\n",
        "}\n",
        "\n",
        "movie_features = movies_entity_type.batch_create_features(\n",
        "    feature_configs=movies_feature_configs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3n5XdK8Xjmw"
      },
      "source": [
        "## Ingest Feature values into Entity types from dataframes\n",
        "\n",
        "You need to ingest feature values into your entity type containing the features. It is so that you can later `read` (online) or `batch serve` (offline) the feature values from the entity type. \n",
        "\n",
        "In this step, you learn how to ingest feature values from a Pandas dataframe into an entity type. You can also import feature values from BigQuery or Google Cloud Storage.\n",
        "\n",
        "### Get data from source\n",
        "\n",
        "Define the public data sources for users and movies and copy them locally into *avro* files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uNrHqiGXrff"
      },
      "outputs": [],
      "source": [
        "GCS_USERS_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro\"\n",
        ")\n",
        "GCS_MOVIES_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro\"\n",
        ")\n",
        "\n",
        "USERS_AVRO_FN = \"users.avro\"\n",
        "MOVIES_AVRO_FN = \"movies.avro\"\n",
        "\n",
        "! gsutil cp $GCS_USERS_AVRO_URI $USERS_AVRO_FN\n",
        "! gsutil cp $GCS_MOVIES_AVRO_URI $MOVIES_AVRO_FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd6Z0jfR5OW5"
      },
      "source": [
        "### Load data from avro files \n",
        "\n",
        "Load users and movies data from avro files into Pandas dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrB7bnqbZYaC"
      },
      "outputs": [],
      "source": [
        "# Define a class for reading the avro data\n",
        "class AvroReader:\n",
        "    def __init__(self, data_file):\n",
        "        self.avro_reader = DataFileReader(open(data_file, \"rb\"), DatumReader())\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        records = [record for record in self.avro_reader]\n",
        "        return pd.DataFrame.from_records(data=records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdlWJhUt5OW5"
      },
      "outputs": [],
      "source": [
        "# Load users data from avro file\n",
        "users_avro_reader = AvroReader(data_file=USERS_AVRO_FN)\n",
        "users_source_df = users_avro_reader.to_dataframe()\n",
        "print(users_source_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ49cPS35OW5"
      },
      "outputs": [],
      "source": [
        "# Load movies data from avro file\n",
        "movies_avro_reader = AvroReader(data_file=MOVIES_AVRO_FN)\n",
        "movies_source_df = movies_avro_reader.to_dataframe()\n",
        "print(movies_source_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgb0WGwX5OW6"
      },
      "source": [
        "### Ingest Feature values into Entity types\n",
        "\n",
        "Load the feature values into `users` entity type providing the id fields and time field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b813uj5OW6"
      },
      "outputs": [],
      "source": [
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=users_source_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCAdQ3cF5OW6"
      },
      "source": [
        "Load the feature values into `movie` entity type providing the id fields and time field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DYlKe4e5OW6"
      },
      "outputs": [],
      "source": [
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=movies_source_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYLZwao5OW6"
      },
      "source": [
        "## Read/serve Entity's feature values online from Feature Store\n",
        "\n",
        "Feature Store allows [online serving](https://cloud.google.com/vertex-ai/docs/featurestore/serving-online)\n",
        "which lets you read feature values for small batches of entities. It works well when you want to read values of selected features from an entity or multiple entities in an entity type.\n",
        "\n",
        "### Read feature values for users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrR-SY3i58rh"
      },
      "outputs": [],
      "source": [
        "users_read_df = users_entity_type.read(\n",
        "    entity_ids=[\"dave\", \"alice\", \"charlie\", \"bob\", \"eve\"],\n",
        ")\n",
        "print(users_read_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2cfa09ef11d"
      },
      "source": [
        "### Read feature values for movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTW6kBxN5OW7"
      },
      "outputs": [],
      "source": [
        "movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "print(movies_read_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK2Glzkq5OW7"
      },
      "source": [
        "## Batch serve feature values from Feature Store\n",
        "\n",
        "Batch Serving is used to fetch a large batch of feature values for high-throughput, and is typically used for training a model or batch prediction. In this section, you learn how to prepare training examples by using the Feature Store's batch serve function.\n",
        "\n",
        "### Read instances from source file\n",
        "\n",
        "Define the source file and destination file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4k2QVN-5OW7"
      },
      "outputs": [],
      "source": [
        "GCS_READ_INSTANCES_CSV_URI = \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movie_prediction.csv\"\n",
        "READ_INSTANCES_CSV_FN = \"data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f2c558b649f"
      },
      "source": [
        "Copy the instances from the source file to the destination file locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr8XDjk_5OW7"
      },
      "outputs": [],
      "source": [
        "! gsutil cp $GCS_READ_INSTANCES_CSV_URI $READ_INSTANCES_CSV_FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5DW1MFt5OW7"
      },
      "source": [
        "### Load the instances\n",
        "\n",
        "Load the instances from CSV file into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqQVfRnC5OW7"
      },
      "outputs": [],
      "source": [
        "read_instances_df = pd.read_csv(READ_INSTANCES_CSV_FN)\n",
        "print(read_instances_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsgNNH8G5OW8"
      },
      "source": [
        "### Change the data type\n",
        "\n",
        "Change the data type of the timestamp field from `Timestamp` to `Datetime64`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb9ntNEA5OW8"
      },
      "outputs": [],
      "source": [
        "print(\"before: \", read_instances_df[\"timestamp\"].dtype)\n",
        "read_instances_df = read_instances_df.astype({\"timestamp\": \"datetime64\"})\n",
        "print(\"after:  \", read_instances_df[\"timestamp\"].dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1dC5Pc5OW8"
      },
      "source": [
        "### Batch serve feature values from Feature Store\n",
        "\n",
        "Serve the batch response to a dataframe and display the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZSJ-Sbl5OW8"
      },
      "outputs": [],
      "source": [
        "movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "movie_predictions_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN84znoI5OW8"
      },
      "source": [
        "## Read the latest feature values\n",
        "\n",
        "In Feature Store, you access the latest or the last available feature values unless a specific time is provided. Now, you test this feature by ingesting new data to the entity types and reading it from the Feature Store.\n",
        "\n",
        "### Ingest updated feature values\n",
        "\n",
        "Now, you update the feature values by running the following cell. \n",
        "\n",
        "**Note:** For comparison, you can try printing the feature values read from the entity types earlier (those in `movies_read_df` variable). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y-iMUFH5OW9"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe for the new data\n",
        "update_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_03\", 4.3], [\"movie_04\", 4.8]],\n",
        "    columns=[\"movie_id\", \"average_rating\"],\n",
        ")\n",
        "\n",
        "# Ingest the new data from the dataframe\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\"],\n",
        "    feature_time=datetime.datetime.now(),\n",
        "    df_source=update_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s47WCIvL5OW9"
      },
      "source": [
        "### Fetch the latest feature values\n",
        "\n",
        "Reading from the entity type gives you the updated feature values from the latest ingestion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2IPEY7S5OW9"
      },
      "outputs": [],
      "source": [
        "update_movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "print(update_movies_read_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1YGRNsW5OW9"
      },
      "source": [
        "## Point-in-time correctness\n",
        "\n",
        "Vertex AI Feature Store captures feature values for a feature at a specific point in time. In case there are missing values in your past data, you can backfill them using batch serving.\n",
        "\n",
        "### Missing data\n",
        "Recall that response from the batch serve from last ingestion has some missing data in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueXYomBr5OW-"
      },
      "outputs": [],
      "source": [
        "# Print the response\n",
        "print(movie_predictions_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abQRF6mx5OW-"
      },
      "source": [
        "### Backfill/correct point-in-time data\n",
        "\n",
        "Impute the missing data based on the timestamps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehZhc4ZP5OW-"
      },
      "outputs": [],
      "source": [
        "# Impute the users data\n",
        "backfill_users_df = pd.DataFrame(\n",
        "    data=[[\"bob\", 34, \"Male\", [\"Drama\"], \"2020-02-13 09:35:15\"]],\n",
        "    columns=[\"user_id\", \"age\", \"gender\", \"liked_genres\", \"update_time\"],\n",
        ")\n",
        "backfill_users_df = backfill_users_df.astype({\"update_time\": \"datetime64\"})\n",
        "print(backfill_users_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhdTzl5k5OW-"
      },
      "outputs": [],
      "source": [
        "# Impute the movies data\n",
        "backfill_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_04\", 4.2, \"The Dark Knight\", \"Action\", \"2020-02-13 09:35:15\"]],\n",
        "    columns=[\"movie_id\", \"average_rating\", \"title\", \"genres\", \"update_time\"],\n",
        ")\n",
        "backfill_movies_df = backfill_movies_df.astype({\"update_time\": \"datetime64\"})\n",
        "print(backfill_movies_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXb4JUhu5OW-"
      },
      "source": [
        "### Ingest the backfilled/corrected data\n",
        "\n",
        "Ingest the imputed point-in-time data from dataframe to the entity types in feature store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM1ejZMa5OW-"
      },
      "outputs": [],
      "source": [
        "# Ingest the users data\n",
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_users_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBnrNbv75OW-"
      },
      "outputs": [],
      "source": [
        "# Ingest the users data\n",
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e62Ku6W5OW_"
      },
      "source": [
        "### Fetch the latest data\n",
        "Batch serve the latest ingested data with backfill/correction to a dataframe to ensure the feature store is updated. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3njvLv2wbZok"
      },
      "outputs": [],
      "source": [
        "backfill_movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "print(backfill_movie_predictions_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBTNfN8vxz4x"
      },
      "outputs": [],
      "source": [
        "# Delete the feature store\n",
        "movie_predictions_feature_store.delete(force=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk-feature-store-pandas.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
