{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Using Vertex AI Feature Store with pandas dataFrame\n",
        "\n",
        "<table align=\"left\">\n",
        "    <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "    \n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> \n",
        "        Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/feature_store/sdk-feature-store-pandas.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook introduces pandas support for `Vertex AI Feature Store` using Vertex AI SDK. For pre-requisites and introduction on Vertex AI SDK and Feature Store native support, please go through this [Colab notebook](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/feature_store/sdk-feature-store.ipynb). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxF5JWRVT5PP"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to use `Vertex AI Feature Store` with pandas dataFrame.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex AI Feature Store`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Create a Vertex AI Feature Store.\n",
        "- Create Vertex AI Entity Type resources for the Vertex AI Feature Store.\n",
        "- Create Vertex AI Feature resources for corresponding Vertex AI Entity Type resources.\n",
        "- Ingest feature values from pandas dataFrame into Vertex AI Feature Store's Entity Type resources.\n",
        "- Read Vertex AI Entity Types Feature values from online Feature Store into pandas dataFrame.\n",
        "- Batch serve feature values from your Feature Store into pandas dataFrame.\n",
        "\n",
        "You also learn how Vertex AI Feature Store can be useful in the below scenarios:\n",
        "\n",
        "- Online serving with updated feature values.\n",
        "- Point-in-time correctness to fetch feature values for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ZNLaf6T0lN"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial uses a movie recommendation dataset as an example throughout all the notebooks including this one. The original task is to train a model to predict if a user is going to watch a movie and serve the model online."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W2Bj_QpT2Ud"
      },
      "source": [
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEdiXsJg0XY"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install additional packages\n",
        "\n",
        "To run this notebook, you need to install the following packages for Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The Vertex AI Workbench Notebook product has specific requirements\n",
        "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
        "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
        "    \"/opt/deeplearning/metadata/env_version\"\n",
        ")\n",
        "\n",
        "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_WORKBENCH_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "    \n",
        "! pip install -U {USER_FLAG} --upgrade google-cloud-aiplatform \\\n",
        "                                        google-cloud-bigquery \\\n",
        "                                        google-cloud-bigquery-storage \\\n",
        "                                        avro \\\n",
        "                                        pyarrow \\\n",
        "                                        pandas -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the packages, you need to restart the notebook kernel so that it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcdfccf50581"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
        "    # Get your GCP project id from gcloud\n",
        "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID:\", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09021c90b34c"
      },
      "outputs": [],
      "source": [
        "! gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f41eda68c379"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
        "\n",
        "- Americas: `us-central1`\n",
        "- Europe: `europe-west4`\n",
        "- Asia Pacific: `asia-east1`\n",
        "\n",
        "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
        "\n",
        "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c615e53149f"
      },
      "outputs": [],
      "source": [
        "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
        "\n",
        "if REGION == \"[your-region]\":\n",
        "    REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr--iN2kAylZ"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using Google Cloud Notebooks**, your environment is already\n",
        "authenticated. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "**If you are using Colab**, run the cell below and follow the instructions\n",
        "when prompted to authenticate your account via oAuth.\n",
        "\n",
        "**Otherwise**, follow these steps:\n",
        "\n",
        "1. In the Cloud Console, go to the [**Create service account key**\n",
        "   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n",
        "\n",
        "2. Click **Create service account**.\n",
        "\n",
        "3. In the **Service account name** field, enter a name, and\n",
        "   click **Create**.\n",
        "\n",
        "4. In the **Grant this service account access to project** section, click the **Role** drop-down list. Type \"Vertex AI\"\n",
        "into the filter box, and select\n",
        "   **Vertex AI Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "5. Click **Create**. A JSON file that contains your key downloads to your\n",
        "local environment.\n",
        "\n",
        "6. Enter the path to your service account key as the\n",
        "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# If on Vertex AI Workbench, then don't execute this code\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
        "    \"DL_ANACONDA_HOME\"\n",
        "):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdct_Lm7x2I_"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UvxYyGUimKw"
      },
      "source": [
        "## Create Vertex AI Feature Store resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buQBIv3ZL3A0"
      },
      "source": [
        "### Create a Vertex AI Feature Store\n",
        "\n",
        "The method to create a Vertex AI Feature Store returns a\n",
        "[long-running operation](https://google.aip.dev/151) (LRO). An LRO starts an asynchronous job. LROs are returned for other API\n",
        "methods too, such as updating or deleting a featurestore. Running the code cell creates a featurestore and prints the process logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6uIWQeoBSr8"
      },
      "outputs": [],
      "source": [
        "movie_predictions_feature_store = aiplatform.Featurestore.create(\n",
        "    featurestore_id=\"movie_predictions\",\n",
        "    online_store_fixed_node_count=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpmJq75zXjmT"
      },
      "source": [
        "### Create the Vertex AI Entity Type resources\n",
        "\n",
        "Vertex AI Entity Types can be created within a Vertex AI Feature Store resource. Below, you create the `Users` entity type and `Movies` entity type. Process logs are printed in the output for each cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU0oXvINBgPV"
      },
      "outputs": [],
      "source": [
        "users_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"users\",\n",
        "    description=\"Users entity\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPCGFznrFwFy"
      },
      "outputs": [],
      "source": [
        "movies_entity_type = movie_predictions_feature_store.create_entity_type(\n",
        "    entity_type_id=\"movies\",\n",
        "    description=\"Movies entity\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJW4q-0jO2Xf"
      },
      "source": [
        "### Create Vertex AI Feature resources for the Vertex AI Entity Type resources\n",
        "Vertex AI Feature resources can be created within each Vertex AI Entity Type. Add defining features to the `Users` entity type and `Movies` entity type by using the following methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvjwT84iVSps"
      },
      "outputs": [],
      "source": [
        "users_feature_age = users_entity_type.create_feature(\n",
        "    feature_id=\"age\",\n",
        "    value_type=\"INT64\",\n",
        "    description=\"User age\",\n",
        ")\n",
        "\n",
        "users_feature_gender = users_entity_type.create_feature(\n",
        "    feature_id=\"gender\",\n",
        "    value_type=\"STRING\",\n",
        "    description=\"User gender\",\n",
        ")\n",
        "\n",
        "users_feature_liked_genres = users_entity_type.create_feature(\n",
        "    feature_id=\"liked_genres\",\n",
        "    value_type=\"STRING_ARRAY\",\n",
        "    description=\"An array of genres this user liked\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llTT9_Dgbac2"
      },
      "outputs": [],
      "source": [
        "movies_feature_configs = {\n",
        "    \"title\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The title of the movie\",\n",
        "    },\n",
        "    \"genres\": {\n",
        "        \"value_type\": \"STRING\",\n",
        "        \"description\": \"The genre of the movie\",\n",
        "    },\n",
        "    \"average_rating\": {\n",
        "        \"value_type\": \"DOUBLE\",\n",
        "        \"description\": \"The average rating for the movie, range is [1.0-5.0]\",\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhfOKJL_BvuM"
      },
      "outputs": [],
      "source": [
        "movie_features = movies_entity_type.batch_create_features(\n",
        "    feature_configs=movies_feature_configs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3n5XdK8Xjmw"
      },
      "source": [
        "## Ingest feature values into Entity Type from a pandas dataFrame\n",
        "\n",
        "You need to ingest feature values into your entity type containing the features, so you can later `read` (online) or `batch serve` (offline) the feature values from the entity type. In this step, you learn how to ingest feature values from a Pandas DataFrame into an entity type. You can also import feature values from BigQuery or Cloud Storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlqJ-QdTcs6W"
      },
      "source": [
        "#### Get data from source files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uNrHqiGXrff"
      },
      "outputs": [],
      "source": [
        "GCS_USERS_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro\"\n",
        ")\n",
        "GCS_MOVIES_AVRO_URI = (\n",
        "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro\"\n",
        ")\n",
        "\n",
        "USERS_AVRO_FN = \"users.avro\"\n",
        "MOVIES_AVRO_FN = \"movies.avro\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqIH_bS-5OW5"
      },
      "outputs": [],
      "source": [
        "! gsutil cp $GCS_USERS_AVRO_URI $USERS_AVRO_FN\n",
        "! gsutil cp $GCS_MOVIES_AVRO_URI $MOVIES_AVRO_FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd6Z0jfR5OW5"
      },
      "source": [
        "#### Load Avro files into pandas dataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrB7bnqbZYaC"
      },
      "outputs": [],
      "source": [
        "from avro.datafile import DataFileReader\n",
        "from avro.io import DatumReader\n",
        "\n",
        "\n",
        "class AvroReader:\n",
        "    def __init__(self, data_file):\n",
        "        self.avro_reader = DataFileReader(open(data_file, \"rb\"), DatumReader())\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        records = [record for record in self.avro_reader]\n",
        "        return pd.DataFrame.from_records(data=records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdlWJhUt5OW5"
      },
      "outputs": [],
      "source": [
        "users_avro_reader = AvroReader(data_file=USERS_AVRO_FN)\n",
        "users_source_df = users_avro_reader.to_dataframe()\n",
        "print(users_source_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ49cPS35OW5"
      },
      "outputs": [],
      "source": [
        "movies_avro_reader = AvroReader(data_file=MOVIES_AVRO_FN)\n",
        "movies_source_df = movies_avro_reader.to_dataframe()\n",
        "print(movies_source_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgb0WGwX5OW6"
      },
      "source": [
        "#### Ingest feature values into *Users* Entity Type resource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b813uj5OW6"
      },
      "outputs": [],
      "source": [
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=users_source_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCAdQ3cF5OW6"
      },
      "source": [
        "#### Ingest Feature Values into *Movies* Entity Type resource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DYlKe4e5OW6"
      },
      "outputs": [],
      "source": [
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=movies_source_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYLZwao5OW6"
      },
      "source": [
        "## Online serving feature values from Vertex AI Feature Store\n",
        "\n",
        "Vertex AI Feature Store allows [online serving](https://cloud.google.com/vertex-ai/docs/featurestore/serving-online)\n",
        "which lets you read feature values for small batches of entities. It works well when you want to read values of selected features from an entity or multiple entities in an entity type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrR-SY3i58rh"
      },
      "outputs": [],
      "source": [
        "users_read_df = users_entity_type.read(\n",
        "    entity_ids=[\"dave\", \"alice\", \"charlie\", \"bob\", \"eve\"],\n",
        ")\n",
        "print(users_read_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTW6kBxN5OW7"
      },
      "outputs": [],
      "source": [
        "movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "print(movies_read_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK2Glzkq5OW7"
      },
      "source": [
        "## Batch serve featurevalues from Vertex AI Feature Store\n",
        "\n",
        "Batch serving is used to fetch a large batch of feature values for high-throughput, and is typically used for training a model or batch prediction. In this section, you learn how to prepare training examples by using the Feature Store's batch serve function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxsotHUe5OW7"
      },
      "source": [
        "#### Read instances from source file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4k2QVN-5OW7"
      },
      "outputs": [],
      "source": [
        "GCS_READ_INSTANCES_CSV_URI = \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movie_prediction.csv\"\n",
        "READ_INSTANCES_CSV_FN = \"data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr8XDjk_5OW7"
      },
      "outputs": [],
      "source": [
        "! gsutil cp $GCS_READ_INSTANCES_CSV_URI $READ_INSTANCES_CSV_FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5DW1MFt5OW7"
      },
      "source": [
        "#### Load CSV file into a pandas dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqQVfRnC5OW7"
      },
      "outputs": [],
      "source": [
        "read_instances_df = pd.read_csv(READ_INSTANCES_CSV_FN)\n",
        "print(read_instances_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsgNNH8G5OW8"
      },
      "source": [
        "#### Change the dtype of `Timestamp` to `Datetime64`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb9ntNEA5OW8"
      },
      "outputs": [],
      "source": [
        "print(\"before: \", read_instances_df[\"timestamp\"].dtype)\n",
        "read_instances_df = read_instances_df.astype({\"timestamp\": \"datetime64\"})\n",
        "print(\"after:  \", read_instances_df[\"timestamp\"].dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1dC5Pc5OW8"
      },
      "source": [
        "#### Batch serve feature values from Movie Predictions Feature Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZSJ-Sbl5OW8"
      },
      "outputs": [],
      "source": [
        "movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "movie_predictions_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29gLNORP5OW8"
      },
      "source": [
        "## Read the updated Feature Value resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN84znoI5OW8"
      },
      "source": [
        "#### Feature Values from last ingestion\n",
        "Recall read from the Entity Type shows Feature Values from the last ingestion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtmshq_n5OW9"
      },
      "outputs": [],
      "source": [
        "print(movies_read_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feTUJjqG5OW9"
      },
      "source": [
        "#### Ingest updated Feature Value resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y-iMUFH5OW9"
      },
      "outputs": [],
      "source": [
        "update_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_03\", 4.3], [\"movie_04\", 4.8]],\n",
        "    columns=[\"movie_id\", \"average_rating\"],\n",
        ")\n",
        "print(update_movies_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKKhSzUc5OW9"
      },
      "outputs": [],
      "source": [
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\"],\n",
        "    feature_time=datetime.datetime.now(),\n",
        "    df_source=update_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s47WCIvL5OW9"
      },
      "source": [
        "#### Read the latest Feature Values\n",
        "Read from the Entity Type shows updated Feature values from the latest ingestion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2IPEY7S5OW9"
      },
      "outputs": [],
      "source": [
        "update_movies_read_df = movies_entity_type.read(\n",
        "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
        "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
        ")\n",
        "print(update_movies_read_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsvCRzn_5OW9"
      },
      "source": [
        "## Point-in-Time Correctness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1YGRNsW5OW9"
      },
      "source": [
        "#### Missing data\n",
        "Recall Batch Serve from the last ingestion has some missing data in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueXYomBr5OW-"
      },
      "outputs": [],
      "source": [
        "print(movie_predictions_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abQRF6mx5OW-"
      },
      "source": [
        "#### Backfill/Correct point-in-time data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehZhc4ZP5OW-"
      },
      "outputs": [],
      "source": [
        "backfill_users_df = pd.DataFrame(\n",
        "    data=[[\"bob\", 34, \"Male\", [\"Drama\"], \"2020-02-13 09:35:15\"]],\n",
        "    columns=[\"user_id\", \"age\", \"gender\", \"liked_genres\", \"update_time\"],\n",
        ")\n",
        "backfill_users_df = backfill_users_df.astype({\"update_time\": \"datetime64\"})\n",
        "print(backfill_users_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhdTzl5k5OW-"
      },
      "outputs": [],
      "source": [
        "backfill_movies_df = pd.DataFrame(\n",
        "    data=[[\"movie_04\", 4.2, \"The Dark Knight\", \"Action\", \"2020-02-13 09:35:15\"]],\n",
        "    columns=[\"movie_id\", \"average_rating\", \"title\", \"genres\", \"update_time\"],\n",
        ")\n",
        "backfill_movies_df = backfill_movies_df.astype({\"update_time\": \"datetime64\"})\n",
        "print(backfill_movies_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXb4JUhu5OW-"
      },
      "source": [
        "#### Ingest backfilled/corrected point-in-time data from dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM1ejZMa5OW-"
      },
      "outputs": [],
      "source": [
        "users_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_users_df,\n",
        "    entity_id_field=\"user_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBnrNbv75OW-"
      },
      "outputs": [],
      "source": [
        "movies_entity_type.ingest_from_df(\n",
        "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
        "    feature_time=\"update_time\",\n",
        "    df_source=backfill_movies_df,\n",
        "    entity_id_field=\"movie_id\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e62Ku6W5OW_"
      },
      "source": [
        "#### Latest ingestion with imputed missing data\n",
        "Batch Serve from the latest ingestion with backfill/correction has reduced missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3njvLv2wbZok"
      },
      "outputs": [],
      "source": [
        "backfill_movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
        "    serving_feature_ids={\n",
        "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
        "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
        "    },\n",
        "    read_instances_df=read_instances_df,\n",
        ")\n",
        "print(backfill_movie_predictions_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "You can also keep the project but delete the featurestore by running the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBTNfN8vxz4x"
      },
      "outputs": [],
      "source": [
        "movie_predictions_feature_store.delete(force=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk-feature-store-pandas.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
