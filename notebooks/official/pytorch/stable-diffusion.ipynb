{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8123d0a-6bc1-4a7b-95aa-fabfb94af47c",
   "metadata": {
    "id": "18ebbd838e32"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f836b-0cd3-4198-9163-515aef9ae5fc",
   "metadata": {},
   "source": [
    "# Run and Deploy Stable Diffusion 2.0 model in Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4f2d5-71a3-4881-a48f-3c593894f40b",
   "metadata": {
    "id": "50c4f2d5-71a3-4881-a48f-3c593894f40b"
   },
   "source": [
    "### Install TorchServe and AI Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22460d37-17c7-4a01-88b2-e5bacafdf971",
   "metadata": {
    "id": "22460d37-17c7-4a01-88b2-e5bacafdf971",
    "outputId": "ba2c653a-1fa0-4a24-a536-42da0138aaa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "torchserve\n",
    "torch-model-archiver\n",
    "torch-workflow-archiver\n",
    "google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dd180-d439-406c-b18d-771c426b6a54",
   "metadata": {
    "id": "870dd180-d439-406c-b18d-771c426b6a54"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6feef-c3b7-46a9-9a94-ab10fdb631ec",
   "metadata": {
    "id": "b8c6feef-c3b7-46a9-9a94-ab10fdb631ec"
   },
   "outputs": [],
   "source": [
    "!mkdir model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbb0e0-40e6-43a0-a38e-edc54323da51",
   "metadata": {
    "id": "eafbb0e0-40e6-43a0-a38e-edc54323da51"
   },
   "source": [
    "### Create the customized handler that will be used by the TorchServe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94567a87-9d74-4c87-a749-306ddaf01b61",
   "metadata": {
    "id": "94567a87-9d74-4c87-a749-306ddaf01b61",
    "outputId": "945a45c3-0091-43ea-f1e0-73564aa94b9d"
   },
   "outputs": [],
   "source": [
    "%%writefile model_artifacts/handler.py\n",
    "\n",
    "\"\"\"Customized handler for stable diffusion 2.\"\"\"\n",
    "import base64\n",
    "import logging\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "model_id = 'stabilityai/stable-diffusion-2'\n",
    "\n",
    "\n",
    "class ModelHandler(BaseHandler):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.initialized = False\n",
    "    self.map_location = None\n",
    "    self.device = None\n",
    "    self.use_gpu = True\n",
    "    self.store_avg = True\n",
    "    self.pipe = None\n",
    "\n",
    "  def initialize(self, context):\n",
    "    \"\"\"Initializes the pipe.\"\"\"\n",
    "    properties = context.system_properties\n",
    "    gpu_id = properties.get('gpu_id')\n",
    "\n",
    "    self.map_location, self.device, self.use_gpu = \\\n",
    "      ('cuda', torch.device('cuda:' + str(gpu_id)),\n",
    "       True) if torch.cuda.is_available() else \\\n",
    "        ('cpu', torch.device('cpu'), False)\n",
    "\n",
    "    # Use the Euler scheduler here instead\n",
    "    scheduler = EulerDiscreteScheduler.from_pretrained(model_id,\n",
    "                                                       subfolder='scheduler')\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id,\n",
    "                                                   scheduler=scheduler,\n",
    "                                                   torch_dtype=torch.float16)\n",
    "    pipe = pipe.to('cuda')\n",
    "    # Uncomment the following line to reduce the GPU memory usage.\n",
    "    # pipe.enable_attention_slicing()\n",
    "    self.pipe = pipe\n",
    "\n",
    "    self.initialized = True\n",
    "\n",
    "  def preprocess(self, requests):\n",
    "    \"\"\"Noting to do here.\"\"\"\n",
    "    logger.info('requests: %s', requests)\n",
    "    return requests\n",
    "\n",
    "  def inference(self, preprocessed_data, *args, **kwargs):\n",
    "    \"\"\"Run the inference.\"\"\"\n",
    "    images = []\n",
    "    for pd in preprocessed_data:\n",
    "      prompt = pd['prompt']\n",
    "      images.extend(self.pipe(prompt).images)\n",
    "    return images\n",
    "\n",
    "  def postprocess(self, output_batch):\n",
    "    \"\"\"Converts the images to base64 string.\"\"\"\n",
    "    postprocessed_data = []\n",
    "    for op in output_batch:\n",
    "      fp = BytesIO()\n",
    "      op.save(fp, format='JPEG')\n",
    "      postprocessed_data.append(base64.b64encode(fp.getvalue()).decode('utf-8'))\n",
    "      fp.close()\n",
    "    return postprocessed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba496ba-0004-4ba6-a984-3c54a03f036e",
   "metadata": {
    "id": "bba496ba-0004-4ba6-a984-3c54a03f036e"
   },
   "source": [
    "### Create TorchServe model archive file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3ee32-ddfc-4633-83f7-912b4ca211bd",
   "metadata": {
    "id": "e7b3ee32-ddfc-4633-83f7-912b4ca211bd"
   },
   "outputs": [],
   "source": [
    "!torch-model-archiver \\\n",
    "  -f \\\n",
    "  --model-name stable_diffusion_2 \\\n",
    "  --version 1.0 \\\n",
    "  --handler model_artifacts/handler.py \\\n",
    "  --export-path model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c42d7-c725-4822-b310-86e50ac615c2",
   "metadata": {
    "id": "4c8c42d7-c725-4822-b310-86e50ac615c2"
   },
   "source": [
    "### Create the TorchServe config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21b32f-b2c5-4ce0-9cd2-45551409c3a2",
   "metadata": {
    "id": "8b21b32f-b2c5-4ce0-9cd2-45551409c3a2",
    "outputId": "5560c515-eeed-4c41-a715-89a69eece206"
   },
   "outputs": [],
   "source": [
    "%%writefile model_artifacts/config.properties\n",
    "\n",
    "service_envelope=json\n",
    "inference_address=http://0.0.0.0:7080\n",
    "management_address=http://0.0.0.0:7081"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d19376-a188-41e1-a66d-e983f6885cd8",
   "metadata": {
    "id": "76d19376-a188-41e1-a66d-e983f6885cd8"
   },
   "source": [
    "### Optional: local test. (Do not run now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7192a-5dba-444d-a848-fb4403358191",
   "metadata": {
    "id": "daf7192a-5dba-444d-a848-fb4403358191",
    "outputId": "dca8a0b2-d4a1-4fc9-8ab0-79b3f87c3c1b"
   },
   "outputs": [],
   "source": [
    "# !torchserve \\\n",
    "#   --start \\\n",
    "#   --ts-config model_artifacts/config.properties \\\n",
    "#   --model-store model_artifacts \\\n",
    "#   --models stable_diffusion_2.mar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10a534-80d4-4f97-8d53-b7d9ca1169e3",
   "metadata": {
    "id": "3a10a534-80d4-4f97-8d53-b7d9ca1169e3"
   },
   "source": [
    "### Create the Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab028fbe-2aa6-42e4-9cd3-a4c48d74339f",
   "metadata": {
    "id": "ab028fbe-2aa6-42e4-9cd3-a4c48d74339f",
    "outputId": "9579cb83-e496-45d0-baaa-7c3fcff1ec20"
   },
   "outputs": [],
   "source": [
    "%%writefile model_artifacts/Dockerfile\n",
    "\n",
    "FROM pytorch/torchserve:latest-gpu\n",
    "\n",
    "# install dependencies\n",
    "RUN python3 -m pip install --upgrade pip\n",
    "RUN pip3 install diffusers transformers accelerate scipy safetensors\n",
    "\n",
    "USER model-server\n",
    "\n",
    "# copy model\n",
    "COPY ./stable_diffusion_2.mar /home/model-server/\n",
    "COPY ./config.properties /home/model-server/\n",
    "\n",
    "# expose health and prediction listener ports from the image\n",
    "EXPOSE 7080\n",
    "EXPOSE 7081\n",
    "\n",
    "# run Torchserve HTTP serve to respond to prediction requests\n",
    "CMD [\"torchserve\", \\\n",
    "     \"--start\", \\\n",
    "     \"--ts-config=/home/model-server/config.properties\", \\\n",
    "     \"--models\", \\\n",
    "     \"stable_diffusion_2.mar\", \\\n",
    "     \"--model-store\", \\\n",
    "     \"/home/model-server\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca67c39-9d14-4c67-a780-6865beda8bd5",
   "metadata": {
    "id": "7ca67c39-9d14-4c67-a780-6865beda8bd5",
    "outputId": "377db2d1-0771-42b2-b303-bdef771114fc"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"yuti-test\"  # <---CHANGE THIS TO YOUR PROJECT\n",
    "BUCKET_NAME = \"gs://yuti-test-stable-diffusion\"  # <---CHANGE THIS TO YOUR BUCKET\n",
    "APP_NAME = \"stable_diffusion_2\"\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
    "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea9ceb-6aee-40bf-8594-5847d6607d74",
   "metadata": {
    "id": "d0ea9ceb-6aee-40bf-8594-5847d6607d74"
   },
   "source": [
    "### Build the docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb7439-c924-4d8d-bfba-3b0dcdd78905",
   "metadata": {
    "id": "4cfb7439-c924-4d8d-bfba-3b0dcdd78905",
    "outputId": "5fef67b4-dff7-4f22-980b-917fa9bed32d"
   },
   "outputs": [],
   "source": [
    "!docker build \\\n",
    "  --tag=$CUSTOM_PREDICTOR_IMAGE_URI \\\n",
    "  ./model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f112c54-0865-4b38-942c-faea7efb0171",
   "metadata": {
    "id": "4f112c54-0865-4b38-942c-faea7efb0171"
   },
   "source": [
    "### Optional: Test the docker locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811ebfe-b22e-45b4-bf46-a68f94d65dcb",
   "metadata": {
    "id": "0811ebfe-b22e-45b4-bf46-a68f94d65dcb",
    "outputId": "a90d27bc-9609-4cb3-ca8a-261b3f71aabc"
   },
   "outputs": [],
   "source": [
    "!docker run -t -d --rm -p 7080:7080 --name=stable_diffusion_2 --gpus all $CUSTOM_PREDICTOR_IMAGE_URI\n",
    "!sleep 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d8a65-feae-440d-9a65-31d7fe3ad172",
   "metadata": {
    "id": "7d8d8a65-feae-440d-9a65-31d7fe3ad172",
    "outputId": "bb3557a9-a28a-4d12-ca48-433d8197d3ad"
   },
   "outputs": [],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc7e45-54d6-4ab2-9987-8bdad45bd5ff",
   "metadata": {
    "id": "50fc7e45-54d6-4ab2-9987-8bdad45bd5ff"
   },
   "source": [
    "### Sends the curl command request to the local docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3afaf3-900a-4c60-aa6c-38459d3163d7",
   "metadata": {
    "id": "ee3afaf3-900a-4c60-aa6c-38459d3163d7",
    "outputId": "8edadee2-ff8a-4743-8999-44c370f473fa"
   },
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "  -d '{\"instances\": [{\"prompt\": \"plane\"}] }' \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  http://localhost:7080/predictions/stable_diffusion_2 \\\n",
    "  -o img4.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac0728-ac66-4ec6-a866-fdb5ea6ee6d4",
   "metadata": {
    "id": "4aac0728-ac66-4ec6-a866-fdb5ea6ee6d4"
   },
   "source": [
    "### Convert the json to jpeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8ba9b-6534-4c2f-b2d3-d7e58c1ad954",
   "metadata": {
    "id": "d0e8ba9b-6534-4c2f-b2d3-d7e58c1ad954"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "with open('img4.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    with open('img4.jpg', 'wb') as g:\n",
    "        g.write(base64.b64decode(data['predictions'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4c3ac-9c3d-43ea-8f32-0749b842afba",
   "metadata": {
    "id": "44c4c3ac-9c3d-43ea-8f32-0749b842afba",
    "outputId": "e222b09e-a4a4-44d6-cd26-0ee2660bccea"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image('img4.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2766ac7-a016-42e7-bd64-6f9feadbc467",
   "metadata": {
    "id": "c2766ac7-a016-42e7-bd64-6f9feadbc467"
   },
   "source": [
    "### Push to the Vertex AI endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a6b48-7142-4c0c-8376-ec07974cf458",
   "metadata": {
    "id": "7f9a6b48-7142-4c0c-8376-ec07974cf458",
    "outputId": "cc75718b-3a76-48ab-9a4f-d7d648d362b5"
   },
   "outputs": [],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151a761-9079-4f1f-96e3-9f80b9a3d427",
   "metadata": {
    "id": "9151a761-9079-4f1f-96e3-9f80b9a3d427"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e6ac0-8dea-4edd-b17b-051564c3ec62",
   "metadata": {
    "id": "993e6ac0-8dea-4edd-b17b-051564c3ec62"
   },
   "outputs": [],
   "source": [
    "VERSION = 1\n",
    "model_display_name = f\"{APP_NAME}-v{VERSION}\"\n",
    "model_description = \"stable_diffusion_2 container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33903b5-24b0-4629-9af3-8dcca8d326c6",
   "metadata": {
    "id": "e33903b5-24b0-4629-9af3-8dcca8d326c6",
    "outputId": "9536987b-3ca1-46ce-f3c7-fb030ac63c62"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87521ad-7425-4d4f-8b80-1fabbfb91ec4",
   "metadata": {
    "id": "b87521ad-7425-4d4f-8b80-1fabbfb91ec4",
    "outputId": "416c5894-87b6-4313-8b01-132742ef6415"
   },
   "outputs": [],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693352b-e1a8-4013-aaad-1d882f145472",
   "metadata": {
    "id": "c693352b-e1a8-4013-aaad-1d882f145472",
    "outputId": "4a53f6f8-9ed1-4fae-f627-efd5d8d14b88"
   },
   "outputs": [],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "accelerator_type = \"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 1\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3b43f-ef1f-448f-89ee-b6bbc4dbceac",
   "metadata": {
    "id": "a6b3b43f-ef1f-448f-89ee-b6bbc4dbceac"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae17b76-f589-4130-b83a-04386fae4f47",
   "metadata": {
    "id": "9ae17b76-f589-4130-b83a-04386fae4f47",
    "outputId": "a7afe89f-1baa-4586-ba6b-5673b193ad8a"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > instances.json <<END\n",
    "{\n",
    "   \"instances\": [\n",
    "     {\n",
    "       \"prompt\": \"Ironman is riding a spaceship to explore the universe.\"\n",
    "     }\n",
    "   ]\n",
    "}\n",
    "END\n",
    "\n",
    "PROJECT_ID=\"578676399349\"  # <---CHANGE THIS TO YOUR PROJECT Number\n",
    "ENDPOINT_ID=\"7560580602169131008\"  # <---CHANGE THIS TO YOUR ENDPOINT\n",
    "INPUT_DATA_FILE=\"instances.json\"\n",
    "\n",
    "curl \\\n",
    "-X POST \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/us-central1/endpoints/${ENDPOINT_ID}:predict \\\n",
    "-d \"@${INPUT_DATA_FILE}\" -o img5.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b9a2e-d19c-471c-866b-cb8b2473ced8",
   "metadata": {
    "id": "464b9a2e-d19c-471c-866b-cb8b2473ced8"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "with open('img5.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    with open('img5.jpg', 'wb') as g:\n",
    "        g.write(base64.b64decode(data['predictions'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09b5f7-598d-48c1-b18c-1e73ac5eee04",
   "metadata": {
    "id": "df09b5f7-598d-48c1-b18c-1e73ac5eee04",
    "outputId": "c1388d77-ca9e-4f2f-a28b-9b386552ea45"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image('img5.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3605f2c-6308-4fad-a8b8-89a57bf2f852",
   "metadata": {
    "id": "f3605f2c-6308-4fad-a8b8-89a57bf2f852"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
