{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c4f2d5-71a3-4881-a48f-3c593894f40b",
   "metadata": {
    "id": "50c4f2d5-71a3-4881-a48f-3c593894f40b"
   },
   "source": [
    "### Install TorchServe and AI Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22460d37-17c7-4a01-88b2-e5bacafdf971",
   "metadata": {
    "id": "22460d37-17c7-4a01-88b2-e5bacafdf971",
    "outputId": "05acf8b2-f4b6-4959-dcbe-1a7369ad56d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchserve\n",
      "  Downloading torchserve-0.7.0-py3-none-any.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-model-archiver\n",
      "  Downloading torch_model_archiver-0.7.0-py3-none-any.whl (14 kB)\n",
      "Collecting torch-workflow-archiver\n",
      "  Downloading torch_workflow_archiver-0.2.6-py3-none-any.whl (12 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from torchserve) (9.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchserve) (23.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from torchserve) (5.9.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from torchserve) (0.38.4)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=0dac2c3101791f5adcc41f340d80a46ff9ab785ea7b42cbb69d6716c87c0dca9\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/52/2a/fc/520209cfa6448febd490720a0b09036cb367628f7c4e9cc172\n",
      "Successfully built future\n",
      "Installing collected packages: torch-workflow-archiver, enum-compat, future, torchserve, torch-model-archiver\n",
      "Successfully installed enum-compat-0.0.3 future-0.18.3 torch-model-archiver-0.7.0 torch-workflow-archiver-0.2.6 torchserve-0.7.0\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.7/site-packages (1.21.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.8.1)\n",
      "Collecting packaging<22.0.0dev,>=14.3\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: shapely<2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.8.5.post1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.22.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.7.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (3.4.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.58.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.16.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.28.2)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.51.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.7/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.4.8)\n",
      "Installing collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "Successfully installed packaging-21.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torchserve torch-model-archiver torch-workflow-archiver\n",
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870dd180-d439-406c-b18d-771c426b6a54",
   "metadata": {
    "id": "870dd180-d439-406c-b18d-771c426b6a54"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c6feef-c3b7-46a9-9a94-ab10fdb631ec",
   "metadata": {
    "id": "b8c6feef-c3b7-46a9-9a94-ab10fdb631ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model_artifacts’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbb0e0-40e6-43a0-a38e-edc54323da51",
   "metadata": {
    "id": "eafbb0e0-40e6-43a0-a38e-edc54323da51"
   },
   "source": [
    "### Create the customized handler that will be used by the TorchServe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94567a87-9d74-4c87-a749-306ddaf01b61",
   "metadata": {
    "id": "94567a87-9d74-4c87-a749-306ddaf01b61",
    "outputId": "9bbfea0e-3792-4e83-afb4-177671ca3f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_artifacts/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_artifacts/handler.py\n",
    "\n",
    "\"\"\"Customized handler for stable diffusion 2.\"\"\"\n",
    "import base64\n",
    "import logging\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "model_id = 'stabilityai/stable-diffusion-2'\n",
    "\n",
    "\n",
    "class ModelHandler(BaseHandler):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.initialized = False\n",
    "    self.map_location = None\n",
    "    self.device = None\n",
    "    self.use_gpu = True\n",
    "    self.store_avg = True\n",
    "    self.pipe = None\n",
    "\n",
    "  def initialize(self, context):\n",
    "    \"\"\"Initializes the pipe.\"\"\"\n",
    "    properties = context.system_properties\n",
    "    gpu_id = properties.get('gpu_id')\n",
    "\n",
    "    self.map_location, self.device, self.use_gpu = \\\n",
    "      ('cuda', torch.device('cuda:' + str(gpu_id)),\n",
    "       True) if torch.cuda.is_available() else \\\n",
    "        ('cpu', torch.device('cpu'), False)\n",
    "\n",
    "    # Use the Euler scheduler here instead\n",
    "    scheduler = EulerDiscreteScheduler.from_pretrained(model_id,\n",
    "                                                       subfolder='scheduler')\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id,\n",
    "                                                   scheduler=scheduler,\n",
    "                                                   torch_dtype=torch.float16)\n",
    "    pipe = pipe.to('cuda')\n",
    "    # Uncomment the following line to reduce the GPU memory usage.\n",
    "    # pipe.enable_attention_slicing()\n",
    "    self.pipe = pipe\n",
    "\n",
    "    self.initialized = True\n",
    "\n",
    "  def preprocess(self, requests):\n",
    "    \"\"\"Noting to do here.\"\"\"\n",
    "    logger.info('requests: %s', requests)\n",
    "    return requests\n",
    "\n",
    "  def inference(self, preprocessed_data, *args, **kwargs):\n",
    "    \"\"\"Run the inference.\"\"\"\n",
    "    images = []\n",
    "    for pd in preprocessed_data:\n",
    "      prompt = pd['prompt']\n",
    "      images.extend(self.pipe(prompt).images)\n",
    "    return images\n",
    "\n",
    "  def postprocess(self, output_batch):\n",
    "    \"\"\"Converts the images to base64 string.\"\"\"\n",
    "    postprocessed_data = []\n",
    "    for op in output_batch:\n",
    "      fp = BytesIO()\n",
    "      op.save(fp, format='JPEG')\n",
    "      postprocessed_data.append(base64.b64encode(fp.getvalue()).decode('utf-8'))\n",
    "      fp.close()\n",
    "    return postprocessed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba496ba-0004-4ba6-a984-3c54a03f036e",
   "metadata": {
    "id": "bba496ba-0004-4ba6-a984-3c54a03f036e"
   },
   "source": [
    "### Create TorchServe model archive file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b3ee32-ddfc-4633-83f7-912b4ca211bd",
   "metadata": {
    "id": "e7b3ee32-ddfc-4633-83f7-912b4ca211bd"
   },
   "outputs": [],
   "source": [
    "!torch-model-archiver \\\n",
    "  -f \\\n",
    "  --model-name model \\\n",
    "  --version 1.0 \\\n",
    "  --handler model_artifacts/handler.py \\\n",
    "  --export-path model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1789667-b3bd-4135-80ae-cebf3ef36d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handler.py  model.mar\n"
     ]
    }
   ],
   "source": [
    "!ls model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4464d-b585-4f4f-9259-84c56db59624",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_PATH = \"\" # change this to a gcs path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6afa77-7378-4616-82b8-e18133b9a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r model_artifacts $GCS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629d123-830f-4db9-a5b6-b5f534680103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc5876-822c-4e2a-91cd-2b661d82f35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d1829-7376-413b-bd13-8a43ac8ba4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca67c39-9d14-4c67-a780-6865beda8bd5",
   "metadata": {
    "id": "7ca67c39-9d14-4c67-a780-6865beda8bd5",
    "outputId": "6e517fc4-436b-415d-b4b6-53803ab0cf3b"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"yuti-test\"  # <---CHANGE THIS TO YOUR PROJECT\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"us-docker.pkg.dev/vertex-ai/prediction/pytorch-gpu.1-12:latest\"\n",
    "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2766ac7-a016-42e7-bd64-6f9feadbc467",
   "metadata": {
    "id": "c2766ac7-a016-42e7-bd64-6f9feadbc467"
   },
   "source": [
    "### Push to the Vertex AI endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151a761-9079-4f1f-96e3-9f80b9a3d427",
   "metadata": {
    "id": "9151a761-9079-4f1f-96e3-9f80b9a3d427"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e6ac0-8dea-4edd-b17b-051564c3ec62",
   "metadata": {
    "id": "993e6ac0-8dea-4edd-b17b-051564c3ec62"
   },
   "outputs": [],
   "source": [
    "VERSION = 1\n",
    "model_display_name = \"stable_diffusion_2\"\n",
    "model_description = \"stable_diffusion_2 container\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33903b5-24b0-4629-9af3-8dcca8d326c6",
   "metadata": {
    "id": "e33903b5-24b0-4629-9af3-8dcca8d326c6",
    "outputId": "884b5c86-a3e5-47c0-c344-68fb5b415d65"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    artifact_uri=GCS_PATH,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87521ad-7425-4d4f-8b80-1fabbfb91ec4",
   "metadata": {
    "id": "b87521ad-7425-4d4f-8b80-1fabbfb91ec4",
    "outputId": "ae7fed39-0755-4157-ee2a-6874aeb11417"
   },
   "outputs": [],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693352b-e1a8-4013-aaad-1d882f145472",
   "metadata": {
    "id": "c693352b-e1a8-4013-aaad-1d882f145472",
    "outputId": "ad476893-204c-4e45-be1f-f5845454eb04"
   },
   "outputs": [],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "accelerator_type = \"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 1\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3b43f-ef1f-448f-89ee-b6bbc4dbceac",
   "metadata": {
    "id": "a6b3b43f-ef1f-448f-89ee-b6bbc4dbceac"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae17b76-f589-4130-b83a-04386fae4f47",
   "metadata": {
    "id": "9ae17b76-f589-4130-b83a-04386fae4f47",
    "outputId": "8967ad1b-60a9-4584-99bd-995009ce29e2"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > instances.json <<END\n",
    "{\n",
    "   \"instances\": [\n",
    "     {\n",
    "       \"prompt\": \"Ironman is riding a spaceship to explore the universe.\"\n",
    "     }\n",
    "   ]\n",
    "}\n",
    "END\n",
    "\n",
    "PROJECT_ID=\"578676399349\"  # <---CHANGE THIS TO YOUR PROJECT Number\n",
    "ENDPOINT_ID=\"7560580602169131008\"  # <---CHANGE THIS TO YOUR ENDPOINT\n",
    "INPUT_DATA_FILE=\"instances.json\"\n",
    "\n",
    "curl \\\n",
    "-X POST \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/us-central1/endpoints/${ENDPOINT_ID}:predict \\\n",
    "-d \"@${INPUT_DATA_FILE}\" -o img5.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b9a2e-d19c-471c-866b-cb8b2473ced8",
   "metadata": {
    "id": "464b9a2e-d19c-471c-866b-cb8b2473ced8"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "with open('img5.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    with open('img5.jpg', 'wb') as g:\n",
    "        g.write(base64.b64decode(data['predictions'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09b5f7-598d-48c1-b18c-1e73ac5eee04",
   "metadata": {
    "id": "df09b5f7-598d-48c1-b18c-1e73ac5eee04",
    "outputId": "72582036-8584-4c8f-d3bc-ffe96cb89cae"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image('img5.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3605f2c-6308-4fad-a8b8-89a57bf2f852",
   "metadata": {
    "id": "f3605f2c-6308-4fad-a8b8-89a57bf2f852"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
